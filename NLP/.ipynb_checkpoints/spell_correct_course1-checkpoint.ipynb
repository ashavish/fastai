{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Spelling Corrector from NLP Course 1 - fast.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "text = words(open(\"words_set_spelling.txt\").read())\n",
    "words_vocab = Counter(text)\n",
    "word_bigrams = nltk.bigrams(text)\n",
    "word_bigrams_vocab = Counter(word_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(word):\n",
    "    '''\n",
    "    Find the probability of a word\n",
    "    '''\n",
    "    return (words_vocab[word]/sum(words_vocab.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_prob(words):\n",
    "    '''\n",
    "    Out of a set of words get word with max probability\n",
    "    '''\n",
    "    P = {word:prob(word) for word in words}\n",
    "    return max(P,key=P.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    '''\n",
    "    Out of a set of words, return the words which are present in the vocab\n",
    "    '''\n",
    "    return [word for word in words if word in words_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possibilities(word):\n",
    "    '''\n",
    "    All the possibilities that exist 1/2 edit distance away \n",
    "    '''\n",
    "    letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    splits = [[word[:i],word[i:]] for i in range(len(word))]\n",
    "    deletes = [L + R[1:] for L,R in splits]\n",
    "    substitutes = [L + l + R[1:] for L,R in splits for l in letters]\n",
    "    swaps = [L + R[1]+ R[0] + R[2:] for L,R in splits if len(R)>=2]\n",
    "    inserts = [L + l + R for L,R in splits for l in letters]\n",
    "    return [word] + deletes + swaps + inserts + substitutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(word):\n",
    "    return max_prob(known(possibilities(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cheek'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction(\"chegk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'substitute'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction(\"substtute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_bigrams_vocab[(\"the\",\"project\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction with bigram context. Previous word\n",
    "\n",
    "words_vocab = Counter(text)\n",
    "word_bigrams = nltk.bigrams(text)\n",
    "word_bigrams_vocab = Counter(word_bigrams)\n",
    "\n",
    "def prob_context(word,prev_word):\n",
    "    '''\n",
    "    Find the probability of a word given a context\n",
    "    P(A|B) = P(A U B)/ P(B)\n",
    "    '''\n",
    "    return word_bigrams_vocab[(word,prev_word)]/(words_vocab[word])\n",
    "\n",
    "def max_prob_context(words,prev_word):\n",
    "    '''\n",
    "    Out of a set of words get word with max probability\n",
    "    '''\n",
    "    P = {word:prob_context(prev_word,word) for word in words}\n",
    "    return max(P,key=P.get)\n",
    "\n",
    "def correction_context(word,prev_word):\n",
    "    return max_prob_context(known(possibilities(word)),prev_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dear'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction_context(\"hear\",prev_word=\"my\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'want'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction_context(\"waant\",prev_word=\"i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
